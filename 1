pseduo mode : https://docs.google.com/document/d/1bBpwwbnUh23N0osGODWlkkiVgQKc_2lZrvbaGx5qFGs/edit?tab=t.0
multi : https://docs.google.com/document/d/13frp5Z8PxB0zJDZaWoW8GIcTFTa0krZLGaLPXq3aPo0/edit?tab=t.0

sudo apt install openjdk-8-jre-headless
sudo apt install openjdk-8-jdk-headless
sudo apt-get install ssh
ssh-keygen -t rsa -P ""
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized.keys
chmod 700 ~/.ssh
chmod 600 ~/.ssh/authorized_keys
ssh localhost

sudo apt-get install pdsh
pdsh -q -w localhost
//cek default rcmd type = ssh, klo nggak pakai step bawah
export PDSH_RCMD_TYPE=ssh
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz
tar -xvf hadoop-3.4.0.tar.gz
mv hadoop-3.4.0 Hadoop
sudo mv Hadoop/ /usr/share/

nano .bashrc

   export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
   export HADOOP_INSTALL=/usr/share/Hadoop
   export PATH=$PATH:$HADOOP_INSTALL/bin
   export PATH=$PATH:$HADOOP_INSTALL/sbin
   export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
   export HADOOP_COMMON_HOME=$HADOOP_INSTALL
   export HADOOP_HDFS_HOME=$HADOOP_INSTALL
   export YARN_HOME=$HADOOP_INSTALL
   export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
   export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib"

source .bashrc

cd /usr/share/Hadoop/etc/hadoop/

nano core-site.xml
   <configuration>
     <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost/</value>
     </property>
   </configuration> 

nano hdfs-site.xml
   <configuration>
     <property>
       <name>dfs.replication</name>
       <value>1</value>
     </property>
     <property>
       <name>dfs.permission</name>
       <value>false</value>
     </property>
   </configuration>
  
nano mapred-site.xml

   <configuration>
     <property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
     </property>
   </configuration>

nano yarn-site.xml
    <configuration>
       <property>
       <name>yarn.resourcemanager.hostname</name>
       <value>localhost</value>
    </property>
    <property>
       <name>yarn.nodemanager.aux-services</name>
    </property>
    <property>
       <value>mapreduce_shuffle</value>
       <name>yarn.nodemanager.auxservices.mapreduce.shuffle.clas</name>
       <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    </configuration>
   
nano  hadoop-env.sh
    # The java implementation to use 
   export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

cd /usr/share/Hadoop/bin
    hadoop namenode -format

cd /usr/share/Hadoop/sbin
    ./start-all.sh

jps 
   ./
//multi cluster

cd /usr/share/Hadoop/etc/hadoop/
mkdir –p hdfstmp
mkdir –p hdfs/namenode
mkdir –p hdfs/datanode
chmod 755 hdfstmp
chmod 755 hdfs/namenode
chmod 755 hdfs/datanode

nano core-site.xml
   <configuration>
      <property>
         <name>hadoop.tmp.dir</name>
         <value>/home/adiba/hdfstmp</value>
       </property>
       <property>
          <name>fs.default.name</name>
          <value>hdfs://master:8020</value>
       </property>
       <property>
          <name>fs.defaultFS</name>
          <value>hdfs://master:8020</value>
       </property>
 </configuration>

 nano hdfs-site.xml
   <configuration>
      <property>
         <name>dfs.replication</name>
         <value>2</value>
      </property>   
      <property>
         <name>dfs.permissions</name>
         <value>false</value>
      </property>
      <property>
         <name>fs.default.name</name>
         <value>hdfs://master:8020</value>
      </property>    
      <property>
         <name>dfs.datanode.data.dir</name>
         <value>file:///home/adiba/hdfs/datanode</value>
         <final>true</final>
      </property>    
      <property>
         <name>dfs.namenode.name.dir</name>
         <value>file:///home/adiba/hdfs/namenode</value>
         <final>true</final>
   </property>
 </configuration>

nano mapred-site.xml
<configuration>
    <property>
       <name>mapred.job.tracker</name>
       <value>hdfs://master:8021</value>
    </property>
    <property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
    </property>
 </configuration>



 nano yarn-site.xml
    <configuration>
       <property>
          <name>yarn.resourcemanager.hostname</name>
           <value>master</value>
       </property>
       <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
       </property>
       <property>
          <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
          <value>org.apache.hadoop.mapred.ShuffleHandler</value>
       </property>
    </configuration>









